{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MAIN FUNCTIONS\n",
    "\n",
    "import requests # allows us to fetch URLs\n",
    "import unicodedata # allows unicode transformations\n",
    "import re # regex for advanced string transformations\n",
    "\n",
    "# This function simply creates the url, in string form, and stores it to the list of urls\n",
    "def make_lnkd_urls(username, url_list):\n",
    "    url_list.append(\"https://www.linkedin.com/in/\" + username)\n",
    "\n",
    "# enter string vars for 'first' name\n",
    "## and 'last' name to run it like c-breezy\n",
    "def get_lnkd_username(first, last, name_list, url_list):\n",
    "    \n",
    "    # in the \"url\" variable, you can add various phrases that will help further define\n",
    "    ## your search\n",
    "    # the \"uber\" and \"LinkedIn\" clauses are examples of this\n",
    "    url = \"https://www.google.com/search?q=\" + first + '+' + last + \"+uber+linkedin\"\n",
    "    response = requests.get(url) # get the html of that url\n",
    "    # convert from unicode to string\n",
    "    string_v = unicodedata.normalize('NFKD', response.text).encode('ascii','ignore')\n",
    "    # use regex\n",
    "    m = re.search('https://www.linkedin.com/in/(.+?)&', string_v)\n",
    "    if m:\n",
    "        # name_list contains a list of usernames\n",
    "        name_list.append(m.group(1))\n",
    "        # call the make_lnkd_urls function to convert the username into a url and store it\n",
    "        make_lnkd_urls(m.group(1), url_list)  \n",
    "    else:\n",
    "        print \"Nothing found for: \", first, last\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['davidw294', 'jamwang', 'traviskalanick', 'ellennaruse', 'katyma']\n",
      "                                            0\n",
      "0       https://www.linkedin.com/in/davidw294\n",
      "1         https://www.linkedin.com/in/jamwang\n",
      "2  https://www.linkedin.com/in/traviskalanick\n",
      "3     https://www.linkedin.com/in/ellennaruse\n",
      "4          https://www.linkedin.com/in/katyma\n"
     ]
    }
   ],
   "source": [
    "# test script\n",
    "import pandas as pd\n",
    "\n",
    "# IMPORTANT\n",
    "## Must create 2 lists that will collect the information gathered through the scraping process\n",
    "un_list = []\n",
    "url_list = []\n",
    "\n",
    "get_lnkd_username(\"david hulu\", \"wang\", un_list, url_list)\n",
    "get_lnkd_username(\"james\", \"wang\", un_list, url_list)\n",
    "get_lnkd_username(\"travis\", \"kalanick\", un_list, url_list)\n",
    "get_lnkd_username(\"ellen\", \"naruse\", un_list, url_list)\n",
    "get_lnkd_username(\"katy\", \"ma\", un_list, url_list)\n",
    "print un_list\n",
    "\n",
    "data = pd.DataFrame(url_list)\n",
    "print data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
